defaults: 
  - esm2_lora_contact_650m

_target_: esm2_lora_contactconv_template
name: "esm2 lora with conv refiner and template"
cnn_kernel_size: 7
contact_self_attention_heads: 4
contact_cross_attention_heads: 4
unfreeze_lora: False

learning_rate: 5e-4  # Lower learning rate for larger model
weight_decay: 1e-4 

backbone_init_from: ${data_dir}/checkpoints/best_lora_conv_refiner_k7.ckpt